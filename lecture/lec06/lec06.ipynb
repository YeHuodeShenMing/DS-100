{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Wrangling and Regex\n",
    "\n",
    "Adapted from Lisa Yan, Will Fithian, Joseph Gonzalez, Deborah Nolan, Sam Lau\n",
    "\n",
    "Updated by Bella Crouch\n",
    "\n",
    "Working with text: applying string methods and regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:15.363920Z",
     "start_time": "2018-02-02T15:15:14.337886Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: Canonicalizing County Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Witt County</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lac qui Parle County</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lewis and Clark County</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St John the Baptist Parish</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       County State\n",
       "0              De Witt County    IL\n",
       "1        Lac qui Parle County    MN\n",
       "2      Lewis and Clark County    MT\n",
       "3  St John the Baptist Parish    LS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeWitt</td>\n",
       "      <td>16798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lac Qui Parle</td>\n",
       "      <td>8067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lewis &amp; Clark</td>\n",
       "      <td>55716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St. John the Baptist</td>\n",
       "      <td>43044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 County  Population\n",
       "0                DeWitt       16798\n",
       "1         Lac Qui Parle        8067\n",
       "2         Lewis & Clark       55716\n",
       "3  St. John the Baptist       43044"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states = pd.read_csv(\"data/county_and_state.csv\")\n",
    "populations = pd.read_csv(\"data/county_and_population.csv\")\n",
    "\n",
    "# display allows us to view a DataFrame without returning it as an object\n",
    "display(states)\n",
    "display(populations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these DataFrames share a \"County\" column. Unfortunately, formatting differences mean that we can't directly merge the two DataFrames using the \"County\"s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [County, State, Population]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.merge(populations, left_on=\"County\", right_on=\"County\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas String Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address this, we can **canonicalize** the \"County\" string data to apply a common formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              dewitt\n",
       "1         lacquiparle\n",
       "2       lewisandclark\n",
       "3    stjohnthebaptist\n",
       "Name: County, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0              dewitt\n",
       "1         lacquiparle\n",
       "2       lewisandclark\n",
       "3    stjohnthebaptist\n",
       "Name: County, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def canonicalize_county(county_series):\n",
    "    return (county_series.str.lower()               # lowercase\n",
    "            .str.replace(' ', '')                   # remove space\n",
    "            .str.replace('&', 'and')                # replace &\n",
    "            .str.replace('.', '')                   # remove dot\n",
    "            .str.replace('county', '')              # remove \"county\"\n",
    "            .str.replace('parish', '')              # remove \"parish\" \n",
    "            )\n",
    "\n",
    "display(canonicalize_county(states[\"County\"]))\n",
    "display(canonicalize_county(populations[\"County\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Canonical County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Witt County</td>\n",
       "      <td>IL</td>\n",
       "      <td>dewitt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lac qui Parle County</td>\n",
       "      <td>MN</td>\n",
       "      <td>lacquiparle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lewis and Clark County</td>\n",
       "      <td>MT</td>\n",
       "      <td>lewisandclark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St John the Baptist Parish</td>\n",
       "      <td>LS</td>\n",
       "      <td>stjohnthebaptist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       County State  Canonical County\n",
       "0              De Witt County    IL            dewitt\n",
       "1        Lac qui Parle County    MN       lacquiparle\n",
       "2      Lewis and Clark County    MT     lewisandclark\n",
       "3  St John the Baptist Parish    LS  stjohnthebaptist"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Population</th>\n",
       "      <th>Canonical County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeWitt</td>\n",
       "      <td>16798</td>\n",
       "      <td>dewitt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lac Qui Parle</td>\n",
       "      <td>8067</td>\n",
       "      <td>lacquiparle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lewis &amp; Clark</td>\n",
       "      <td>55716</td>\n",
       "      <td>lewisandclark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St. John the Baptist</td>\n",
       "      <td>43044</td>\n",
       "      <td>stjohnthebaptist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 County  Population  Canonical County\n",
       "0                DeWitt       16798            dewitt\n",
       "1         Lac Qui Parle        8067       lacquiparle\n",
       "2         Lewis & Clark       55716     lewisandclark\n",
       "3  St. John the Baptist       43044  stjohnthebaptist"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states[\"Canonical County\"] = canonicalize_county(states[\"County\"])\n",
    "populations[\"Canonical County\"] = canonicalize_county(populations[\"County\"])\n",
    "display(states)\n",
    "display(populations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the merge works as expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County_x</th>\n",
       "      <th>State</th>\n",
       "      <th>Canonical County</th>\n",
       "      <th>County_y</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Witt County</td>\n",
       "      <td>IL</td>\n",
       "      <td>dewitt</td>\n",
       "      <td>DeWitt</td>\n",
       "      <td>16798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lac qui Parle County</td>\n",
       "      <td>MN</td>\n",
       "      <td>lacquiparle</td>\n",
       "      <td>Lac Qui Parle</td>\n",
       "      <td>8067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lewis and Clark County</td>\n",
       "      <td>MT</td>\n",
       "      <td>lewisandclark</td>\n",
       "      <td>Lewis &amp; Clark</td>\n",
       "      <td>55716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St John the Baptist Parish</td>\n",
       "      <td>LS</td>\n",
       "      <td>stjohnthebaptist</td>\n",
       "      <td>St. John the Baptist</td>\n",
       "      <td>43044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     County_x State  Canonical County              County_y  \\\n",
       "0              De Witt County    IL            dewitt                DeWitt   \n",
       "1        Lac qui Parle County    MN       lacquiparle         Lac Qui Parle   \n",
       "2      Lewis and Clark County    MT     lewisandclark         Lewis & Clark   \n",
       "3  St John the Baptist Parish    LS  stjohnthebaptist  St. John the Baptist   \n",
       "\n",
       "   Population  \n",
       "0       16798  \n",
       "1        8067  \n",
       "2       55716  \n",
       "3       43044  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.merge(populations, on=\"Canonical County\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "**Return to Lecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Demo 2: Extracting Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['169.237.46.168 - - [26/Jan/2014:10:47:58 -0800] \"GET /stat141/Winter04/ HTTP/1.1\" 200 2585 \"http://anson.ucdavis.edu/courses/\"\\n',\n",
       " '193.205.203.3 - - [2/Feb/2005:17:23:6 -0800] \"GET /stat141/Notes/dim.html HTTP/1.0\" 404 302 \"http://eeyore.ucdavis.edu/stat141/Notes/session.html\"\\n',\n",
       " '169.237.46.240 - \"\" [3/Feb/2006:10:18:37 -0800] \"GET /stat141/homework/Solutions/hw1Sol.pdf HTTP/1.1\"\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_fname = 'data/log.txt'\n",
    "with open(log_fname, 'r') as f:\n",
    "    log_lines = f.readlines()\n",
    "log_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to extract the day, month, year, hour, minutes, seconds, and timezone. Looking at the data, we see that these items are not in a fixed position relative to the beginning of the string. That is, slicing by some fixed offset isn't going to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26/Jan/2014'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_lines[0][20:31] #  20:31 were determined by trial-and-error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we use the same range for the next log line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Feb/2005:1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_lines[1][20:31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we'll need to use some more sophisticated thinking. Let's focus on only the first line of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'169.237.46.168 - - [26/Jan/2014:10:47:58 -0800] \"GET /stat141/Winter04/ HTTP/1.1\" 200 2585 \"http://anson.ucdavis.edu/courses/\"\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = log_lines[0]\n",
    "first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the data inside the square brackes by splitting string at the square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26/Jan/2014:10:47:58 -0800'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pertinent = (\n",
    "    first.split(\"[\")[1] # remove everything before the first [\n",
    "    .split(']')[0] # Remove everything after the second square ]\n",
    ") # find the text enclosed in square brackets\n",
    "pertinent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day:    26\n",
      "Month:  Jan\n",
      "Rest:   2014:10:47:58 -0800\n"
     ]
    }
   ],
   "source": [
    "day, month,rest  = pertinent.split('/')       # split up the date/month/year \n",
    "\n",
    "print(\"Day:   \", day)\n",
    "print(\"Month: \", month)\n",
    "print(\"Rest:  \", rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:    2014\n",
      "Hour:    10\n",
      "Minute:  47\n",
      "Rest:    58 -0800\n"
     ]
    }
   ],
   "source": [
    "year, hour, minute, rest = rest.split(':')    # split up the hour:minute:second\n",
    "\n",
    "print(\"Year:   \", year)\n",
    "print(\"Hour:   \", hour)\n",
    "print(\"Minute: \", minute)\n",
    "print(\"Rest:   \", rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('26', 'Jan', '2014', '10', '47', '58', '-0800')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seconds, time_zone = rest.split(' ')          # split the timezone after the blank space\n",
    "day, month, year, hour, minute, seconds, time_zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try doing the same thing using pandas `str` methods:\n",
    "\n",
    "Solution below.\n",
    "<details>\n",
    "    \n",
    "```python\n",
    "df = (\n",
    "    logs.str.split(\"[\")\n",
    "        .str[1]\n",
    "        .str.split(\"]\")\n",
    "        .str[0]\n",
    "        .str.split(\"/\", expand=True)\n",
    "        .rename(columns={0: \"Day\", 1: \"Month\", 2: \"Rest\"})\n",
    ")\n",
    "df = (\n",
    "    df.join(df[\"Rest\"].str.split(\":\", expand=True))\n",
    "        .drop(columns=[\"Rest\"])\n",
    "        .rename(columns={0: \"Year\", 1: \"Hour\", 2: \"Minute\", 3: \"Rest\"})\n",
    ")\n",
    "df = (\n",
    "    df.join(df[\"Rest\"].str.split(\" \", expand=True))\n",
    "        .drop(columns=[\"Rest\"])\n",
    "        .rename(columns = {0: \"Seconds\", 1: \"Timezone\"})\n",
    ")\n",
    "\n",
    "print(\"Final Dataframe\")\n",
    "display(df)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    169.237.46.168 - - [26/Jan/2014:10:47:58 -0800...\n",
       "1    193.205.203.3 - - [2/Feb/2005:17:23:6 -0800] \"...\n",
       "2    169.237.46.240 - \"\" [3/Feb/2006:10:18:37 -0800...\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logs = pd.read_csv(\"data/log.txt\", \n",
    "                sep=\"\\t\", \n",
    "                header=None)[0]\n",
    "\n",
    "print(\"Original input!\")\n",
    "display(logs)\n",
    "\n",
    "# finish me\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This worked and you will often see code like this in data cleaning pipelines.  \n",
    "\n",
    "However, **regular expressions** provide a faster and more expressive mechanism to extract strings that match certain patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>\n",
    "\n",
    "**Return to lecture**\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## String Extraction with Regex\n",
    "\n",
    "Python `re.findall` returns a list of all extracted matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123-45-6789', '321-45-6789']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"My social security number is 123-45-6789 bro, or actually maybe itâ€™s 321-45-6789.\";\n",
    "\n",
    "pattern = r\"[0-9]{3}-[0-9]{2}-[0-9]{4}\"\n",
    "\n",
    "re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Now, let's see vectorized extraction in `pandas`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `.str.findall` returns a `Series` of lists of all matches in each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SSN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>987-65-4321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123-45-6789 bro or 321-45-6789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999-99-9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              SSN\n",
       "0                     987-65-4321\n",
       "1                           forty\n",
       "2  123-45-6789 bro or 321-45-6789\n",
       "3                     999-99-9999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ssn = pd.DataFrame(\n",
    "    ['987-65-4321',\n",
    "     'forty',\n",
    "     '123-45-6789 bro or 321-45-6789',\n",
    "     '999-99-9999'],\n",
    "    columns=['SSN'])\n",
    "df_ssn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [987-65-4321]\n",
       "1                            []\n",
       "2    [123-45-6789, 321-45-6789]\n",
       "3                 [999-99-9999]\n",
       "Name: SSN, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> Series of lists\n",
    "pattern = r\"[0-9]{3}-[0-9]{2}-[0-9]{4}\"\n",
    "df_ssn['SSN'].str.findall(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the last expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    987-65-4321\n",
       "1            NaN\n",
       "2    321-45-6789\n",
       "3    999-99-9999\n",
       "Name: SSN, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_ssn['SSN']\n",
    "    .str.findall(pattern)\n",
    "    .str[-1] # Get the last element from each list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "**Return to slides**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "\n",
    "## Extraction Using Regex Capture Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python function `re.findall`, in combination with parentheses returns specific substrings (i.e., **capture groups**) within each matched string, or **match**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"I will meet you at 08:30:00 pm tomorrow\"\"\"       \n",
    "pattern = \".*(\\d\\d):(\\d\\d):(\\d\\d).*\"\n",
    "matches = re.findall(pattern, text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the three capture groups in the first matched string\n",
    "hour, minute, second = matches[0]\n",
    "print(\"Hour:   \", hour)\n",
    "print(\"Minute: \", minute)\n",
    "print(\"Second: \", second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "In `pandas`, we can use `.str.extract` to extract each capture group of **only the first match** of each record into separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to SSNs\n",
    "df_ssn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will extract the first match of all groups\n",
    "pattern_group_mult = r\"([0-9]{3})-([0-9]{2})-([0-9]{4})\" # 3 groups\n",
    "df_ssn['SSN'].str.extract(pattern_group_mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When debugging my code with the `str` accessors I often make a separate series varible so the python tab completion tools can find the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssns = df_ssn['SSN']\n",
    "ssns.str.extract(pattern_group_mult) # <- try shift+tab inside the parens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, `.str.extractall` extracts **all matches** of each record into separate columns. Rows are then MultiIndexed by original record index and match index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> DataFrame, one row per match\n",
    "df_ssn['SSN'].str.extractall(pattern_group_mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "**Return to Slides**\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Canonicalization with Regex (sub, replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regular Python, canonicalize with `re.sub` (standing for \"substitute\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Moo'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '<div><td valign=\"top\">Moo</td></div>'\n",
    "pattern = r\"<[^>]+>\"\n",
    "re.sub(pattern, '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "In `pandas`, canonicalize with `Series.str.replace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;div&gt;&lt;td valign=\"top\"&gt;Moo&lt;/td&gt;&lt;/div&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;a href=\"http://ds100.org\"&gt;Link&lt;/a&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;b&gt;Bold text&lt;/b&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Html\n",
       "0  <div><td valign=\"top\">Moo</td></div>\n",
       "1   <a href=\"http://ds100.org\">Link</a>\n",
       "2                      <b>Bold text</b>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example dataframe of strings\n",
    "df_html = pd.DataFrame(['<div><td valign=\"top\">Moo</td></div>',\n",
    "                   '<a href=\"http://ds100.org\">Link</a>',\n",
    "                   '<b>Bold text</b>'], columns=['Html'])\n",
    "df_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bold text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Html\n",
       "0        Moo\n",
       "1       Link\n",
       "2  Bold text"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Series -> Series\n",
    "df_html[\"Html\"].str.replace(pattern, '', regex=True).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "**Return to lecture**\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Revisiting Text Log Processing using Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python `re` version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = log_lines[0]\n",
    "display(line)\n",
    "\n",
    "pattern = r'\\[(\\d+)\\/(\\w+)\\/(\\d+):(\\d+):(\\d+):(\\d+) (.+)\\]'\n",
    "day, month, year, hour, minute, second, time_zone = re.findall(pattern, line)[0] # get first match\n",
    "day, month, year, hour, minute, second, time_zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pandas` version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(log_lines, columns=['Log'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: `Series.str.findall`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+):(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+):(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+):(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+) (.+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLog\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mfindall(pattern)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "pattern = r'\\[(\\d+)\\/(\\w+)\\/(\\d+):(\\d+):(\\d+):(\\d+) (.+)\\]'\n",
    "df['Log'].str.findall(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Option 2: `Series.str.extractall`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Log'].str.extractall(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrangling either of these two DataFrames into a nice format (like below) is left as an exercise for you! You will do a related problem on the homework.\n",
    "\n",
    "\n",
    "||Day|Month|Year|Hour|Minute|Second|Time Zone|\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|0|26|Jan|2014|10|47|58|-0800|\n",
    "|1|2|Feb|2005|17|23|6|-0800|\n",
    "|2|3|Feb|2006|10|18|37|-0800|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "# Real World Case Study: Restaurant Data\n",
    "\n",
    "In this example, we will show how regexes can allow us to track quantitative data across categories defined by the appearance of various text fields.\n",
    "\n",
    "In this example we'll see how the presence of certain keywords can affect quantitative data:\n",
    "\n",
    "> **How do restaurant health scores vary as a function of the number of violations that mention a particular keyword?** \n",
    "> <br/>\n",
    "> (e.g., unclean surfaces, vermin, permits, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vio = pd.read_csv('data/violations.csv', header=0, names=['bid', 'date', 'desc'])\n",
    "desc = vio['desc']\n",
    "vio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = desc.value_counts()\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of different descriptions!! Can we **canonicalize** at all? Let's explore two sets of 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hmmm...\n",
    "counts[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regular expressions to cut out the extra info in square braces.\n",
    "vio['clean_desc'] = (vio['desc']\n",
    "             .str.replace(r'\\s*\\[.*\\]$', '', regex=True)\n",
    "             .str.strip()       # removes leading/trailing whitespace\n",
    "             .str.lower())\n",
    "vio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canonicalizing definitely helped\n",
    "vio['clean_desc'].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vio['clean_desc'].value_counts().head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our research question:\n",
    "\n",
    "> **How do restaurant health scores vary as a function of the number of violations that mention a particular keyword?** \n",
    "> <br/>\n",
    "> (e.g., unclean surfaces, vermin, permits, etc.)\n",
    "\n",
    "<br/>\n",
    "\n",
    "Below, we use regular expressions and `df.assign()` ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html?highlight=assign#pandas.DataFrame.assign)) to **method chain** our creation of new boolean features, one per keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regular expressions to assign new features for the presence of various keywords\n",
    "# regex metacharacter | \n",
    "with_features = (vio\n",
    " .assign(is_unclean     = vio['clean_desc'].str.contains('clean|sanit'))\n",
    " .assign(is_high_risk = vio['clean_desc'].str.contains('high risk'))\n",
    " .assign(is_vermin    = vio['clean_desc'].str.contains('vermin'))\n",
    " .assign(is_surface   = vio['clean_desc'].str.contains('wall|ceiling|floor|surface'))\n",
    " .assign(is_human     = vio['clean_desc'].str.contains('hand|glove|hair|nail'))\n",
    " .assign(is_permit    = vio['clean_desc'].str.contains('permit|certif'))\n",
    ")\n",
    "with_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "### EDA\n",
    "\n",
    "That's the end of our text wrangling. Now let's do some more analysis to analyze restaurant health as a function of the number of violation keywords.\n",
    "\n",
    "To do so we'll first group so that our **granularity** is one inspection for a business on particular date. This effectively counts the number of violations by keyword for a given inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'with_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m count_features \u001b[38;5;241m=\u001b[39m (\u001b[43mwith_features\u001b[49m\n\u001b[0;32m      2\u001b[0m  \u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m  \u001b[38;5;241m.\u001b[39msum(numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m  \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m count_features\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m255\u001b[39m:\u001b[38;5;241m260\u001b[39m, :]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'with_features' is not defined"
     ]
    }
   ],
   "source": [
    "count_features = (with_features\n",
    " .groupby(['bid', 'date'])\n",
    " .sum(numeric_only=True)\n",
    " .reset_index()\n",
    ")\n",
    "count_features.iloc[255:260, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out our new dataframe in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_features[count_features['is_vermin'] > 1].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll reshape this \"wide\" table into a \"tidy\" table using a pandas feature called `pd.melt` ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.melt.html?highlight=pd%20melt)) which we won't describe in any detail, other than that it's effectively the inverse of `pd.pivot_table`.\n",
    "\n",
    "Our **granularity** is now a violation type for a given inspection (for a business on a particular date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_type_df = pd.melt(count_features, id_vars=['bid', 'date'],\n",
    "            var_name='feature', value_name='num_vios')\n",
    "\n",
    "# show a particular inspection's results\n",
    "violation_type_df[(violation_type_df['bid'] == 489) & (violation_type_df['date'] == 20150728)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our research question:\n",
    "\n",
    "> **How do restaurant health scores vary as a function of the number of violations that mention a particular keyword?** \n",
    "> <br/>\n",
    "> (e.g., unclean surfaces, vermin, permits, etc.)\n",
    "\n",
    "<br/>\n",
    "\n",
    "We have the second half of this question! Now let's **join** our table with the inspection scores, located in `inspections.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the scores\n",
    "inspection_df = pd.read_csv('data/inspections.csv',\n",
    "                  header=0,\n",
    "                  usecols=[0, 1, 2],\n",
    "                  names=['bid', 'score', 'date'])\n",
    "inspection_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the inspection scores were stored in a separate file from the violation descriptions, we notice that the **primary key** in inspections is (`bid`, `date`)! So we can reference this key in our join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join scores with the table broken down by violation type\n",
    "violation_type_and_scores = (\n",
    "    violation_type_df\n",
    "    .merge(inspection_df, on=['bid', 'date'])\n",
    ")\n",
    "violation_type_and_scores.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "Let's plot the distribution of scores, broken down by violation counts, for each inspection feature (`is_clean`, `is_high_risk`, `is_vermin`, `is_surface`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will learn this syntax next week. Focus on interpreting for now.\n",
    "sns.catplot(x='num_vios', y='score',\n",
    "               col='feature', col_wrap=2,\n",
    "               kind='box',\n",
    "               data=violation_type_and_scores);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can observe:\n",
    "* The inspection score generally goes down with increasing numbers of violations, as expected.\n",
    "* Depending on the violation keyword, inspections scores on average go down at slightly different rates.\n",
    "* For example, that if a restaurant inspection involved 2 violations with the keyword \"vermin\", the average score for that inspection would be a little bit below 80."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
