{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4875783-3a1e-47a0-bc8f-675647dfc1e1",
   "metadata": {},
   "source": [
    "# Lecture 5 (Part 2 Examples) â€“ Data 100, Spring 2024\n",
    "\n",
    "Data 100, Spring 2024\n",
    "\n",
    "[Acknowledgments Page](https://ds100.org/fa23/acks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd22501d-8cb4-446f-a393-4c989ffe16cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:15.363920Z",
     "start_time": "2018-02-02T15:15:14.337886Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73babc0f-1958-4b75-9e32-f4788b5d7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "# This option stops scientific notation for pandas\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Silence some spurious seaborn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a193d-131d-43af-92d3-0e189c123994",
   "metadata": {},
   "source": [
    "\n",
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Structure: Other File Formats\n",
    "\n",
    "There are many file types for storing structured data: CSV, TSV, JSON, XML, ASCII, SAS...\n",
    "* Documentation will be your best friend to understand how to process many of these file types.\n",
    "* In lecture, we will cover TSV and JSON since pandas supports them out-of-box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98960f5a-f880-447b-ad8b-629ad06061b4",
   "metadata": {},
   "source": [
    "The `pd.read_csv` function also reads in TSVs if we specify the **delimiter** with parameter `sep='\\t'` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd4a443-a27a-4845-8fd9-f99fad26784f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>No. of TB cases</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>TB incidence</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S. jurisdiction</td>\n",
       "      <td>2019</td>\n",
       "      <td>2020</td>\n",
       "      <td>2021</td>\n",
       "      <td>2019.00</td>\n",
       "      <td>2020.00</td>\n",
       "      <td>2021.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total</td>\n",
       "      <td>8,900</td>\n",
       "      <td>7,173</td>\n",
       "      <td>7,860</td>\n",
       "      <td>2.71</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>87</td>\n",
       "      <td>72</td>\n",
       "      <td>92</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>7.91</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>183</td>\n",
       "      <td>136</td>\n",
       "      <td>129</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0 No. of TB cases Unnamed: 2 Unnamed: 3  TB incidence  \\\n",
       "0  U.S. jurisdiction            2019       2020       2021       2019.00   \n",
       "1              Total           8,900      7,173      7,860          2.71   \n",
       "2            Alabama              87         72         92          1.77   \n",
       "3             Alaska              58         58         58          7.91   \n",
       "4            Arizona             183        136        129          2.51   \n",
       "\n",
       "   Unnamed: 5  Unnamed: 6  \n",
       "0     2020.00     2021.00  \n",
       "1        2.16        2.37  \n",
       "2        1.43        1.83  \n",
       "3        7.92        7.92  \n",
       "4        1.89        1.77  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuberculosis_df_tsv = pd.read_csv(\"data/cdc_tuberculosis.tsv\", sep='\\t')\n",
    "tuberculosis_df_tsv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fa20d2-0cbe-4da7-a3db-dae144a3ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\tNo. of TB cases\\t\\t\\tTB incidence\\t\\t\\n'\n",
      "'U.S. jurisdiction\\t2019\\t2020\\t2021\\t2019\\t2020\\t2021\\n'\n",
      "'Total\\t\"8,900\"\\t\"7,173\"\\t\"7,860\"\\t2.71\\t2.16\\t2.37\\n'\n",
      "'Alabama\\t87\\t72\\t92\\t1.77\\t1.43\\t1.83\\n'\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/cdc_tuberculosis.tsv\", \"r\") as f:\n",
    "    for _, row in zip(range(4), f):\n",
    "        print(repr(row)) # print raw strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d419f25-32c1-4b61-aa05-0c471e01a6cf",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "**Return to Slides**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4697e-8dad-452d-b956-a2687850f655",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br> <br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### JSON\n",
    "The City of Berkeley Open Data [website](https://data.cityofberkeley.info/Health/COVID-19-Confirmed-Cases/xn6j-b766) has a dataset with COVID-19 Confirmed Cases among Berkeley residents by date.\n",
    "\n",
    "Let's first check out this website.\n",
    "\n",
    "Next, let's download this file, saving it as a JSON (note the source URL file type).\n",
    "\n",
    "In the interest of **reproducible data science** we will download the data programatically.  We have defined some helper functions in the [ds100_utils.py](ds100_utils.py) file.  I can then reuse these helper functions in many different notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef1ad7e3-1997-4608-ba45-5d9c706314ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:15.368501Z",
     "start_time": "2018-02-02T15:15:15.365808Z"
    }
   },
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "from ds100_utils import fetch_and_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632a1946-faa9-4454-9a04-60a24debf374",
   "metadata": {
    "tags": []
   },
   "source": [
    "Occasionally, you will want to modify code that you have imported from a local Python library.  To reimport those modifications you can either use the python importlib library:\n",
    "\n",
    "```python\n",
    "from importlib import reload\n",
    "reload(utils)\n",
    "```\n",
    "\n",
    "or use iPython magic which will intelligently import code when files change:\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fcaf1c5-9b15-4e17-a043-2e60539658cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading... Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/confirmed-cases.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_file = fetch_and_cache(\n",
    "    \"https://data.cityofberkeley.info/api/views/xn6j-b766/rows.json?accessType=DOWNLOAD\",\n",
    "    \"confirmed-cases.json\",\n",
    "    force=False)\n",
    "covid_file          # a file path wrapper object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1552740-b687-4252-93b5-fe7c31cc9080",
   "metadata": {},
   "source": [
    "#### File size\n",
    "\n",
    "Often, I like to start my analysis by getting a rough estimate of the size of the data.  This will help inform the tools I use and how I view the data.  If it is relatively small I might use a text editor or a spreadsheet to look at the data.  If it is larger, I might jump to more programmatic exploration or even used distributed computing tools.\n",
    "\n",
    "However here we will use Python tools to probe the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5731253b-2d3e-460c-ae6a-b6721ee4dd99",
   "metadata": {},
   "source": [
    "Since these seem to be text files I might also want to investigate the number of lines, which often corresponds to the number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18001389-1f08-477b-ada1-79d10faa977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\confirmed-cases.json is 0.003694 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(covid_file, \"is\", os.path.getsize(covid_file) / 1e6, \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adeb25-626e-4bf1-8b7c-44c536941e7e",
   "metadata": {},
   "source": [
    "As part of your workflow, you should also learn some basic Unix commands, as these are often very handy (in fact, there's an entire book called [\"Data Science at the Command Line\"](https://datascienceatthecommandline.com) that explores this idea in depth!).\n",
    "\n",
    "In Jupyter/IPython, you can prefix lines with `!` to execute arbitrary Unix commands, and within those lines, you can refer to Python variables and expressions with the syntax `{expr}`. \n",
    "\n",
    "Here, we use the `ls` command to list files, using the `-lh` flags, which request \"long format with information in human-readable form\". We also use the `wc` command for \"word count\", but with the `-l` flag, which asks for line counts instead of words.\n",
    "\n",
    "These two give us the same information as the code above, albeit in a slightly different form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "476632aa-8a68-4e75-b2d2-db1ae1ab94f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Data\n",
      " Volume Serial Number is 6E17-92CC\n",
      "\n",
      " Directory of d:\\2024CS\\DS100\\sp24-student-main\\lecture\\lec05\\data\n",
      "\n",
      "2024/12/17  11:16             3,694 confirmed-cases.json\n",
      "               1 File(s)          3,694 bytes\n",
      "\n",
      " Directory of d:\\2024CS\\DS100\\sp24-student-main\\lecture\\lec05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File Not Found\n",
      ".Lines was unexpected at this time.\n"
     ]
    }
   ],
   "source": [
    "!dir {covid_file} -File\n",
    "!(Get-Content {covid_file} | Measure-Object -Line).Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ff01f-ad4d-4559-b728-25d74faeaf6e",
   "metadata": {},
   "source": [
    "#### File contents\n",
    "\n",
    "Because we have a text file in a visual IDE like Jupyter/DataHub, I'm going to visually explore the data via the built-in file explorer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b9e72-2fd0-48af-a0f1-a750e9598770",
   "metadata": {},
   "source": [
    "1. To the Jupyter view!\n",
    "\n",
    "2. To the Python view...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8a3c79b-be34-422d-befd-0c2430ec95c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd\"> <html> <head> <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /> <style type=\"text/css\"> html, body { margin: 0; padding: 0; font-family: Verdana, Arial, sans-serif; font-size: 10pt; background-color: #ffffff; } h1, h2 { height: 82px; text-indent: -999em; margin: 0; padding: 0; margin: 0; } div { margin: 0; padding: 0; } div.header { height: 60px; margin-top: 20x; padding: 20px 0px 20px 60px; } div.header span.banner { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAMAAAAKE/YAAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAABFUExURUdwTONNS7ddXeJMS+NMS+NNTONMTONMTOhRUOROTf///z9ESPCko/nx8eZlZeuFhPjg4IeKjWFlaffMy6+xs/O3ts3Oz4Ax7sQAAAAKdFJOUwCx6//sjtFiGz/FiE2uAAAERUlEQVR42u2c607rMBCEiXJ3aYlNyPs/Kj1AobWTetd27MnRzm8qjVbON9N16MuLSCQSiUQikUgkEolEov9DwziOw6Ecj21Tf6nrj2J87Oo7tYew3daP6kb8s9zVjnp001W9IvBZ92ue6wb6XI/1uipk092GaeQD0m95rjtc082maVyCtNueYZ/F4cmgr8l4vEFfBTlqG3eXI2DPzsLpDR979qDf1ISPPTtXzkq9omPPzpVXpdTZxh447i7XQSv1gY09G3cf6ksX5IQZbNx9e1bvyKO2cff+Y1oBY8/F3U0TbsLYuJt+TTuj7pFxd9MZNWEaN1f+BJowG7i7jRoSe06uqEdBJky7hbubLnjFeht3aiNhALBXbeMONmH8g1Z4xbp7hjtQ7D3Lle2EabBwtzpoMOw9z5Vt7JVMmK0arZCxV/lyBRB7FNzBFevOnytwxZqGO7Bi3VByBSxhyLgDwp6vRkMmDAN3MMWagzuYhKk4uANJmD5g0MWLdcfDHQT2eLnyZJ8AjTsA7Hlz5TxrczJGLzgJ463R8+kms6Bgz5cr+nSnBQN7vlx58Oy4LoQ9T42eT5bOAMXahztjm9YAxdqzNXAG7Yy6QML4cKdd00tp7HlxZ1zTc+mE8dZo17N9qLMXa3+NPvknnXuf4N8aEI5H5oQh1GjjfxAzJwyhRmsv8jJjryXU6BVOU4r1bs8iqUYvjmdTtFiT1jOTn3g5sUfcRhPgkbFYE7cGhmY6D/ao6xntJ14+7FG3BppAvFzYI28NZgo88lzUUS/fXOYZ8uqmLYK77wGSiJejWNMv3xzmzcVWN5xttCHBY/+EYW2jLXxMpS7qWJdvs7cuZUkY3pJ0JsJj530C7/JtosJj14RpedvoM8f0XsWavY02ROLtib2We/lmqMTbD3ucXFlhnvc2Zpdizb98m8nE2wt7AbecC5l4exXrkMs3xnO4C/aCLt8040jvUKzpNfrBhSGzYw/ssV/q+Dmmev1uK0ux5uPu92GctZ7Jf530X0sCXuoIU0LshbzUEaaExbpj50r5UYe+axCiZMW6CciVOxu8P0+UMIG4+3b8j3lm5nwiCfbCX+r4ax+a8ZkkCdNG4M5wqkfCYj3W4YOeOSUvZbGuInCnaVuP5NiLyhXD+LaVslh3MbhjVtNU2IvLlSXoTMcW67AavTLqhfe5KOzF5Mr9t4CZm+YRCTNE4O5GPW2M5hesiGKdrUYnxF6+Gp2wWGes0clGnbNGJyvWcTU6WkEJ00fiLnrUIe9Yd9G4i9QHf9RDOdxtJEzFPh1v+T3bCdOwE3wqYNrG3sBMwxKDdhJmZJp+LaML07TnF8JKaDig6Ybflsqr43O6vNqAMn2AI413PqqgOl34MRyCvoqXVR/4dQv9KVyv1EfwfJ01xglpeHuxAQF8/B8JH9qy0+4Cf9d8GPtSOtgv34tEIpFIJBKJRCKRSCRC1Cc7+FG6yGMv9QAAAABJRU5ErkJggg==) no-repeat; width: 60px; height: 60px; float: left; background-size: contain;} div.header div.title { height: 60px; box-sizing: border-box; padding-left: 12px; float: left; padding-top: 2px; } div.header h3 { font-family: Lato; font-size: 24px; font-weight: 800; color: #262626; margin: 0px; } div.header p { padding: 8px 0px 0px 0px; margin: 0px; font-family: Lato; font-size: 15px; color: #7d7d7d; } div.sidebar { width: 195px; height: 200px; float: left; display: none; } div.main { } div.main div.details { padding: 20px 0px 20px 60px; background-color: #f6f6f6; } div.main div.info { padding: 20px 0px 0px 60px; } div.main div.info h3 { margin: 0px; } div.main div.info p { padding: 0px 0px 20px 0px; } </style> <title>Error 403</title> </head> <body class=\"block\"> <div class=\"header\"> <span class=\"banner\"></span> <div class=\"title\"> <h3>Error 403</h3> <p>Web Page Blocked</p> </div> </div> <div class=\"sidebar\"> <h2 class=\"fgd_icon\">block</h2> </div> <div class=\"main\"> <div class=\"details\"> <p> URL: data.cityofberkeley.info/api/views/xn6j-b766/rows.json<br /><br />Client IP: 50.114.155.142<br />Attack ID: 20000009<br />Message ID: 006512608671 </p> </div> <div class=\"info\"> <h3> What happened? </h3> <p> The page cannot be displayed. </p> <h3> What can I do? </h3> <p> Please contact the administrator for additional information. </p> </div> </div> </body> </html>'\n"
     ]
    }
   ],
   "source": [
    "with open(covid_file, \"r\") as f:\n",
    "    for i, row in enumerate(f):\n",
    "        print(repr(row)) # print raw strings\n",
    "        if i >= 4: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab2da5-bac0-4e92-9f1a-de169bf268a7",
   "metadata": {},
   "source": [
    "In the same vein, we can use the `head` Unix command (which is where Pandas' `head` method comes from!) to see the first few lines of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "380cc048-1ba8-47e4-9e08-1ec9be18f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!head -5 {covid_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a508be-6f9f-4631-befa-973640670714",
   "metadata": {},
   "source": [
    "1. Back to the Python view.\n",
    "\n",
    "    In order to load the JSON file into pandas, Let's first do some **EDA** with the Python `json` package to understand the particular structure of this JSON file so that we can decide what (if anything) to load into Pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa0b37-70b7-4eaa-be61-73632928eecb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EDA: Digging into JSON\n",
    "\n",
    "Python has relatively good support for JSON data since it closely matches the internal python object model.  In the following cell we import the entire JSON datafile into a python dictionary using the `json` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e227500a-c56b-41c4-bbe8-60ee0f2ce088",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.441300Z",
     "start_time": "2018-02-02T15:15:19.358900Z"
    }
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(covid_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 4\u001b[0m     covid_json \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Py\\Lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Py\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32md:\\Py\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32md:\\Py\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(covid_file, \"rb\") as f:\n",
    "    covid_json = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27745131-6d69-485a-adcf-928032b0f425",
   "metadata": {},
   "source": [
    "The `covid_json` variable is now a dictionary encoding the data in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "309f570e-8803-40ab-821d-1e654713d89a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.447238Z",
     "start_time": "2018-02-02T15:15:19.443595Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'covid_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mcovid_json\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'covid_json' is not defined"
     ]
    }
   ],
   "source": [
    "type(covid_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9001f7-0198-4035-9901-17e8510e1a67",
   "metadata": {},
   "source": [
    "#### Examine what keys are in the top level json object\n",
    "\n",
    "We can list the keys to determine what data is stored in the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9e1bb-6c88-46d4-9348-29aaa71596b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.680999Z",
     "start_time": "2018-02-02T15:15:19.675696Z"
    }
   },
   "outputs": [],
   "source": [
    "covid_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29129c86-329d-4fbd-b597-07636d059a12",
   "metadata": {},
   "source": [
    "**Observation**: The JSON dictionary contains a `meta` key which likely refers to meta data (data about the data).  Meta data often maintained with the data and can be a good source of additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57339dd9-f9c3-4f1c-81a7-8b1385205af5",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "We can investigate the meta data further by examining the keys associated with the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56a912-6b8a-4c14-b061-24ff7d77fb18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.687295Z",
     "start_time": "2018-02-02T15:15:19.682902Z"
    }
   },
   "outputs": [],
   "source": [
    "covid_json['meta'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb160b9-fa18-4cda-8f7f-615a3fc49581",
   "metadata": {},
   "source": [
    "The `meta` key contains another dictionary called `view`.  This likely refers to meta-data about a particular \"view\" of some underlying database.  We will learn more about views when we study SQL later in the class.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744c900-e203-444f-a5f3-f251788f8412",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.693946Z",
     "start_time": "2018-02-02T15:15:19.690139Z"
    }
   },
   "outputs": [],
   "source": [
    "covid_json['meta']['view'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba1a46c-c8e0-4ea6-94ee-d3d18ade568c",
   "metadata": {},
   "source": [
    "Notice that this a nested/recursive data structure.  As we dig deeper we reveal more and more keys and the corresponding data:\n",
    "\n",
    "```\n",
    "meta\n",
    "|-> data\n",
    "    | ... (haven't explored yet)\n",
    "|-> view\n",
    "    | -> id\n",
    "    | -> name\n",
    "    | -> attribution \n",
    "    ...\n",
    "    | -> description\n",
    "    ...\n",
    "    | -> columns\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014476d7-76d5-4083-a4b1-269ec44e4bff",
   "metadata": {},
   "source": [
    "There is a key called description in the view sub dictionary.  This likely contains a description of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f6ce3-1e53-44dd-98e0-bbfaa6d5483c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.699773Z",
     "start_time": "2018-02-02T15:15:19.695818Z"
    }
   },
   "outputs": [],
   "source": [
    "print(covid_json['meta']['view']['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc878de-79ff-4334-9743-333913d147b1",
   "metadata": {},
   "source": [
    "\n",
    "#### Examining the Data Field for Records\n",
    "\n",
    "We can look at a few entries in the `data` field. This is what we'll load into Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a28da-d05a-498e-8708-b57c1e254a5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.722451Z",
     "start_time": "2018-02-02T15:15:19.717198Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"{i:03} | {covid_json['data'][i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d978eee-6f46-4ad1-8e58-0ea411e94741",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* These look like equal-length records, so maybe `data` is a table!\n",
    "* But what do each of values in the record mean? Where can we find column headers?\n",
    "\n",
    "Back to the metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86fe73-51b2-4774-b68c-08600b09f424",
   "metadata": {},
   "source": [
    "#### Columns Metadata\n",
    "\n",
    "Another potentially useful key in the metadata dictionary is the `columns`.  This returns a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc43323-e27c-4eaa-8867-64a50215ef82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.706171Z",
     "start_time": "2018-02-02T15:15:19.701580Z"
    }
   },
   "outputs": [],
   "source": [
    "covid_json['meta']['view']['columns']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a83d0b-2f21-4641-a494-8956e976ca4e",
   "metadata": {},
   "source": [
    "Let's go back to the file explorer.\n",
    "\n",
    "Based on the contents of this key, what are reasonable names for each column in the `data` table?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6d197-ec8a-4939-a53a-9f1b9b6a8732",
   "metadata": {},
   "source": [
    "You can also get the view that Jupyter provides in the file explorer by using Python. This displays our JSON object as an interacive graphical object with a built-in search box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810bddd-292e-4fa1-9357-ab2f1c6858d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "JSON(covid_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7574d-15b4-4f44-81b0-292ce37c8e81",
   "metadata": {},
   "source": [
    "#### Summary of exploring the JSON file\n",
    "\n",
    "1. The above **metadata** tells us a lot about the columns in the data including column names, potential data anomalies, and a basic statistic. \n",
    "1. Because of its non-tabular structure, JSON makes it easier (than CSV) to create **self-documenting data**, meaning that information about the data is stored in the same file as the data.\n",
    "1. Self documenting data can be helpful since it maintains its own description and these descriptions are more likely to be updated as data changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da4483-77d0-40e1-8a68-8c3367f6ef09",
   "metadata": {},
   "source": [
    "### JSON with pandas\n",
    "\n",
    "After our above EDA, let's finally go about loading the data (not the metadata) into a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a68fa6-ea30-4716-b1ce-b51232534ceb",
   "metadata": {},
   "source": [
    "In the following block of code we:\n",
    "1. Translate the JSON records into a dataframe:\n",
    "\n",
    "    * fields: `covid_json['meta']['view']['columns']`\n",
    "    * records: `covid_json['data']`\n",
    "    \n",
    "1. Remove columns that have no metadata description.  This would be a bad idea in general but here we remove these columns since the above analysis suggests that they are unlikely to contain useful information.\n",
    "1. Examine the `tail` of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e7992-1e89-4df7-ba44-1da412e5aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_json(covid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61dffb3-4d0c-4e72-8b2c-dac07bdf044e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T15:15:19.793306Z",
     "start_time": "2018-02-02T15:15:19.725044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data from JSON and assign column titles\n",
    "covid = pd.DataFrame(\n",
    "    covid_json['data'],\n",
    "    columns=[c['name'] for c in covid_json['meta']['view']['columns']])\n",
    "\n",
    "covid.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6300e4-fb50-442b-a6a6-472f1ba40001",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "**Return to Slides**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337f37b-8661-4ec5-a00a-c953adf86be6",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Temporality\n",
    "\n",
    "Let's briefly look at how we can use pandas `dt` accessors to work with dates/times in a dataset.\n",
    "\n",
    "We will use the dataset from Lab 3: the Berkeley PD Calls for Service dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb38de-c276-41c6-8b5a-97d2a1798961",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = pd.read_csv(\"data/Berkeley_PD_-_Calls_for_Service.csv\")\n",
    "calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5d1af-5520-410c-9d36-182de0f5edaf",
   "metadata": {},
   "source": [
    "Looks like there are three columns with dates/times: `EVENTDT`, `EVENTTM`, and `InDbDate`. \n",
    "\n",
    "Most likely, `EVENTDT` stands for the date when the event took place, `EVENTTM` stands for the time of day the event took place (in 24-hr format), and `InDbDate` is the date this call is recorded onto the database.\n",
    "\n",
    "If we check the data type of these columns, we will see they are stored as strings. We can convert them to `datetime` objects using pandas `to_datetime` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d11c08-b507-4158-ad2c-2b644516d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls[\"EVENTDT\"] = pd.to_datetime(calls[\"EVENTDT\"],\n",
    "                                 format = \"%m/%d/%Y %I:%M:%S %p\")\n",
    "calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261c47d-22ec-4709-a9e2-129b481ec0bf",
   "metadata": {},
   "source": [
    "Now we can use the `dt` accessor on this column.\n",
    "\n",
    "We can get the month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4df05-b134-41cc-8095-9122330ff42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls[\"EVENTDT\"].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58102f15-0e7e-46b5-aaa9-f9bf65cbfbed",
   "metadata": {},
   "source": [
    "Which day of the week the date is on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934245aa-b0c0-40f7-8a44-843e5a342602",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls[\"EVENTDT\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4630a-7fe3-4998-90f9-304e187a5cff",
   "metadata": {},
   "source": [
    "Check the mimimum values to see if there are any suspicious-looking, 70s dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0750f-87d3-491c-a417-5c208527ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls.sort_values(\"EVENTDT\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf089df9-ceef-44d8-a397-fa3d8b119cfe",
   "metadata": {},
   "source": [
    "Doesn't look like it! We are good!\n",
    "\n",
    "\n",
    "We can also do many things with the `dt` accessor like switching time zones and converting time back to UNIX/POSIX time. Check out the documentation on [`.dt` accessor](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dt-accessors) and [time series/date functionality](https://pandas.pydata.org/docs/user_guide/timeseries.html#)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
